There have been many debates about the way to approach the Ethereum 2.0 roadmap, especially as it relates to data. One interesting proposal was called ["Eth1 and Done"](https://ethresear.ch/t/phase-one-and-done-eth2-as-a-data-availability-engine/5269). It was thinking like this, and the ([surprising](https://twitter.com/jinglejamOP/status/1310718738417811459)) success of parallel work on rollups and STARKs which eventually led us to the current "[rollup-centric roadmap](https://ethereum-magicians.org/t/a-rollup-centric-ethereum-roadmap/4698)"

## History

At first, we thought the way to scale Ethereum was to "shard" it all. "Sharding" is a term used when working with big data, where you cut up the DB into lots of small pieces and have each piece do stuff only related to the data it is responsible for storing. You then need some way of making sure that all the different "shards" can occasionally exchange relevant updates with one another so that, if data in one shard reference data in another and gets updated, that other shard can be aware of it.

This was the line of thinking that led to the development of the beacon chain, which was originally intended to be the thing that helped all the different shards talk to one another about stuff happening to the data they were responsible for storing and updating. People were very worried about (i) the complexity and (ii) the user experience of all this. If Maker lives in one shard, and Uniswap in another, how do we quickly and reliably get data about DAI balances into the Uniswap shard and vice versa? There was much gnashing of teeth.

However, we eventually realized that rollups were going to work, and were going to be usable much more quickly than we had originally thought. And, we can do all sorts of intense computation on a rollup, and then just post the state transition (optimistic rollups) or the validity proof (validity rollups) to the beacon chain in order to "anchor" each rollup in the robust and time-proven security of Ethereum. This solves some of the scaling problems we face, and it simplifies cross-shard communication and complexity by reducing the number of shards we need as well as what responsibilities those shards have.

The first issues was that storage (`SSTORE`) on Ethereum was underpriced, and `calldata` was  overpriced. Rollups posted their state transition or proof in the `calldata` of a transaction to their anchor contract on L1, but it was needlessly expensive. 

[EIP 4844](https://ethereum-magicians.org/t/eip-4844-shard-blob-transactions/8430) - protodanksharding - created a new transaction format that includes a "data blob" which can contain a large amount of data which cannot be accessed by the EVM, but whose commitment can be. What is a commitment? It is an efficient way to help validators (Consensus Layer/Beacon Chain) sample the data included in a blob and ensure that it is all available such that Execution Layer clients can include it in shared state.

EI